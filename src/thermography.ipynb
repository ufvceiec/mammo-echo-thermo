{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast cancer detection from thermal imaging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main purpose of this project is to develop a comprehensive decision support system for breast cancer screening."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library import\n",
    "In this section, the libraries that will be used throughout this model will be imported. Keep in mind that part of the libraries used by this program are declared in the files found in `src/scripts/*.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modules are reloaded automatically before entering the execution of code throughout this notebook\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computer.check_available_devices(ignore=True) # Check available devices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data selection\n",
    "To make this model work correctly it will be necessary to extract and save the images found in the `data` folder.\n",
    "\n",
    "In this folder there are two labeled folders that contain all the images to be used:\n",
    "```\n",
    "data\n",
    "├── healthy\n",
    "└── sick\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(\"./data/\") # Data imported into a table\n",
    "\n",
    "data.images.head(3) # Display first 3 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation\n",
    "In the transformation stage, the data is adapted to find the solution to the problem to be solved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, the data obtained previously will be divided to be able to use it for training and to check the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.training, data.test = data.train_test_split(test_size=0.15, random_state=random_state, stratify=True) # Split data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The category distribution is shown for the original, training, and test data\n",
    "data.count_labels(data.images, \"Original\")\n",
    "data.count_labels(data.training, \"Training\")\n",
    "data.count_labels(data.test, \"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of generators\n",
    "Once the data is divided, different transformation techniques are applied on it to expand the size of the dataset in real time while training the model. To apply a correct solution to the problem, the training and validation dataset will be divided into k consecutive folds, while the test dataset will remain fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_validation_generator = data.training_validation_generator(n_splits=5, random_state=random_state) # Generate training and validation generators\n",
    "test_generator = data.test_generator() # Generate test generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter creation\n",
    "Once the necessary generators have been created, the filters are created for their subsequent model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Apply grid search\n",
    "filters = {\n",
    "\t\"original\": lambda x: x,\n",
    "\t\"high\": lambda x: data.get_image_tensor(x, (330, 0, 0), (360, 255, 255)) + data.get_image_tensor(x, (0, 0, 0), (60, 255, 255)),\n",
    "\t\"medium\": lambda x: data.get_image_tensor(x, (60, 0, 0), (130, 255, 255)),\n",
    "\t\"low\": lambda x: data.get_image_tensor(x, (130, 0, 0), (330, 255, 255))\n",
    "}\n",
    "\n",
    "data.show_images(training_validation_generator[0][0], filters, size=3, name=\"Training\") # Show some images from the training generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Mining\n",
    "This section seeks to apply techniques that are capable of extracting useful patterns and then evaluate them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model creation\n",
    "The models with which they are going to work throughout the project are created. In this case three types of models will be used, five for the high temperature model, five for the medium temperature model and finally five for the low temperature model.\n",
    "\n",
    "Keep in mind that the number of models for each type depends on the number of folds that have been made, that is, the number of generators that are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_model = [Model(path=f\"./output/state_{random_state}/high/fold_{index}\", filter=filters[\"high\"]) for index in range(len(training_validation_generator))] # High temperature models creation\n",
    "medium_model = [Model(path=f\"./output/state_{random_state}/medium/fold_{index}\", filter=filters[\"medium\"]) for index in range(len(training_validation_generator))] # Medium temperature models creation\n",
    "low_model = [Model(path=f\"./output/state_{random_state}/low/fold_{index}\", filter=filters[\"low\"]) for index in range(len(training_validation_generator))] # Low temperature models creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[high_model[index].compile() for index in range(len(high_model))] # Compile the high temperature models\n",
    "[medium_model[index].compile() for index in range(len(medium_model))] # Compile the medium temperature models\n",
    "[low_model[index].compile() for index in range(len(low_model))] # Compile the low temperature models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training\n",
    "The created model is trained indicating the times that are going to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[high_model[index].fit(training_validation_generator[index][0], training_validation_generator[index][1], epochs=600, verbose=False) for index in range(len(high_model))] # Train the high temperature models\n",
    "[medium_model[index].fit(training_validation_generator[index][0], training_validation_generator[index][1], epochs=600, verbose=False) for index in range(len(medium_model))] # Train the medium temperature models\n",
    "[low_model[index].fit(training_validation_generator[index][0], training_validation_generator[index][1], epochs=600, verbose=False) for index in range(len(low_model))] # Train the low temperature models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation\n",
    "The trained model is evaluated using the generators created before. In this case, the best weight matrix obtained in the training will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the high temperature model\n",
    "for index in range(len(high_model)):\n",
    "\thigh_model[index].evaluate(training_validation_generator[index][0], title=\"train_generator\", path=None)\n",
    "\thigh_model[index].evaluate(training_validation_generator[index][1], title=\"validation_generator\", path=None)\n",
    "\thigh_model[index].evaluate(test_generator, title=\"test_generator\", path=None)\n",
    "\n",
    "# Evaluate the medium temperature model\n",
    "for index in range(len(medium_model)):\n",
    "\tmedium_model[index].evaluate(training_validation_generator[index][0], title=\"train_generator\", path=None)\n",
    "\tmedium_model[index].evaluate(training_validation_generator[index][1], title=\"validation_generator\", path=None)\n",
    "\tmedium_model[index].evaluate(test_generator, title=\"test_generator\", path=None)\n",
    "\n",
    "# Evaluate the low temperature model\n",
    "for index in range(len(low_model)):\n",
    "\tlow_model[index].evaluate(training_validation_generator[index][0], title=\"train_generator\", path=None)\n",
    "\tlow_model[index].evaluate(training_validation_generator[index][1], title=\"validation_generator\", path=None)\n",
    "\tlow_model[index].evaluate(test_generator, title=\"test_generator\", path=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining the weighted average\n",
    "\n",
    "The three models extracted above are combined to obtain, through the use of differential evolution, the optimal distribution of weights to obtain a future prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_models = [Join(high_model[index], medium_model[index], low_model[index], path=f\"./output/state_{random_state}/join/fold_{index}\") for index in range(len(high_model))] # Models are joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[join_models[index].get_weighted_average(test_generator, iterations=100, tolerance=1e-7) for index in range(len(high_model))] # Compute the weighted average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[join_models[index].evaluate(test_generator, title=\"test_generator\") for index in range(len(high_model))] # Evaluate the weighted average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grad-CAM\n",
    "An activation map of the predictions obtained by the convolutional network is displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The activation map is displayed\n",
    "for index, image in data.test.iterrows():\n",
    "\tjoin_models.visualize_heatmap(image)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a8beb786faeb05718f0030b63e3f9a213e4fc874985a90138c9f4beb79c05e3b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('hinton': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
