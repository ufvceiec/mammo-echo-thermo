{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast cancer detection from thermal imaging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main purpose of this project is to develop a comprehensive decision support system for breast cancer screening."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library import\n",
    "In this section, the libraries that will be used throughout this model will be imported. Keep in mind that part of the libraries used by this program are declared in the files found in `src/scripts/*.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modules are reloaded automatically before entering the execution of code throughout this notebook\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available devices:\n",
      "- CPU: /physical_device:CPU:0\n"
     ]
    }
   ],
   "source": [
    "computer.check_available_devices(ignore=True) # Check available devices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data selection\n",
    "To make this model work correctly it will be necessary to extract and save the images found in the `data` folder.\n",
    "\n",
    "In this folder there are two labeled folders that contain all the images to be used:\n",
    "```\n",
    "data\n",
    "├── healthy\n",
    "└── sick\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./data/healthy/16-TFRON_V16_31-10-2012_8.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./data/healthy/169-TFRON_V173_8-4-2013_0.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./data/healthy/17-TFRON_V17_31-10-2012_6.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image category\n",
       "0  ./data/healthy/16-TFRON_V16_31-10-2012_8.jpg        0\n",
       "1  ./data/healthy/169-TFRON_V173_8-4-2013_0.jpg        0\n",
       "2  ./data/healthy/17-TFRON_V17_31-10-2012_6.jpg        0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Data(\"./data/\", random_state=42) # Data imported into a table\n",
    "\n",
    "data.images.head(3) # Display first 3 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation\n",
    "In the transformation stage, the data is adapted to find the solution to the problem to be solved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, the data obtained previously will be divided to be able to use it for training and to check the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.training, data.test = data.train_test_split(test_size=0.15, stratify=True) # Split data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: [99 96] [0.51 0.49]\n",
      "Training: [84 81] [0.51 0.49]\n",
      "Test: [15 15] [0.5 0.5]\n"
     ]
    }
   ],
   "source": [
    "# The category distribution is shown for the original, training, and test data\n",
    "data.count_labels(data.images, \"Original\")\n",
    "data.count_labels(data.training, \"Training\")\n",
    "data.count_labels(data.test, \"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the data is divided, different transformation techniques are applied on it to expand the size of the dataset in real time while training the model. To apply a correct solution to the problem, the training and validation dataset will be divided into k consecutive folds, while the test dataset will remain fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_validation_generator = data.training_validation_generator(n_splits=5) # Generate training and validation generators\n",
    "test_generator = data.test_generator() # Generate test generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = {\n",
    "\t\"original\": lambda x: x,\n",
    "\t\"red\": lambda x: data.getImageTensor(x, (330, 0, 0), (360, 255, 255)) + data.getImageTensor(x, (0, 0, 0), (60, 255, 255)),\n",
    "\t\"green\": lambda x: data.getImageTensor(x, (60, 0, 0), (130, 255, 255)),\n",
    "\t\"blue\": lambda x: data.getImageTensor(x, (130, 0, 0), (330, 255, 255))\n",
    "}\n",
    "\n",
    "data.show_images(train_generator, filters, \"Training\") # Show some images from the training generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Mining\n",
    "This section seeks to apply techniques that are capable of extracting useful patterns and then evaluate them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model creation\n",
    "The model to be used for the next training is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_model = Model(\"red\", filter=filters[\"red\"], new=False, summary=False, plot=False) # Red model creation\n",
    "green_model = Model(\"green\", filter=filters[\"green\"], new=False, summary=False, plot=False) # Green model creation\n",
    "blue_model = Model(\"blue\", filter=filters[\"blue\"], new=False, summary=False, plot=False) # Blue model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_model.compile() # Compile the red model\n",
    "green_model.compile() # Compile the green model\n",
    "blue_model.compile() # Compile the blue model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training\n",
    "The created model is trained indicating the times that are going to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_model.fit(train_generator, validation_generator, epochs=600, verbose=False, plot=False) # Train the red model\n",
    "green_model.fit(train_generator, validation_generator, epochs=600, verbose=False, plot=False) # Train the green model\n",
    "blue_model.fit(train_generator, validation_generator, epochs=600, verbose=False, plot=False) # Train the blue model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation\n",
    "The trained model is evaluated using the generators created before. In this case, the best weight matrix obtained in the training will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_model.evaluate(train_generator, name=\"train_generator\", path=None) # Evaluate the red model\n",
    "red_model.evaluate(validation_generator, name=\"validation_generator\", path=None) # Evaluate the red model\n",
    "red_model.evaluate(test_generator, name=\"test_generator\", path=None) # Evaluate the red model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "green_model.evaluate(train_generator, name=\"train_generator\", path=None) # Evaluate the green model\n",
    "green_model.evaluate(validation_generator, name=\"validation_generator\", path=None) # Evaluate the green model\n",
    "green_model.evaluate(test_generator, name=\"test_generator\", path=None) # Evaluate the green model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blue_model.evaluate(train_generator, name=\"train_generator\", path=None) # Evaluate the blue model\n",
    "blue_model.evaluate(validation_generator, name=\"validation_generator\", path=None) # Evaluate the blue model\n",
    "blue_model.evaluate(test_generator, name=\"test_generator\", path=None) # Evaluate the blue model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining the weighted average\n",
    "\n",
    "The three models extracted above are combined to obtain, through the use of differential evolution, the optimal distribution of weights to obtain a future prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_models = Join(red_model, green_model, blue_model) # Models are joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_models.get_weighted_average(test_generator, iterations=100, tolerance=1e-7) # Compute the weighted average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_models.evaluate(test_generator, name=\"test_generator\") # Evaluate the weighted average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grad-CAM\n",
    "An activation map of the predictions obtained by the convolutional network is displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The activation map is displayed\n",
    "for index, image in data.test.iterrows():\n",
    "\tjoin_models.visualize_heatmap(image)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a8beb786faeb05718f0030b63e3f9a213e4fc874985a90138c9f4beb79c05e3b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('hinton': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
